{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNkmLbMGZrDPa3jRJ25X4US"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c\n","\n","https://github.com/tintn/vision-transformer-from-scratch\n","\n","https://github.com/ShivamRajSharma/Vision-Transformer\n","\n","https://github.com/dqj5182/vit_cnn_cifar_10_from_scratch\n","\n","<b>      https://github.com/kentaroy47/vision-transformers-cifar10 </b>\n","\n","https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/course_UvA-DL/11-vision-transformer.ipynb"],"metadata":{"id":"VcszfhhcavEc"}},{"cell_type":"code","source":["!pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGaji1_VgI3S","executionInfo":{"status":"ok","timestamp":1702074769925,"user_tz":-210,"elapsed":11664,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"9ca042cb-e0db-4bf1-b683-080baae585a6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m41.0/44.6 kB\u001b[0m \u001b[31m983.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m933.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.7.0\n"]}]},{"cell_type":"markdown","source":["# VIT"],"metadata":{"id":"XsJr-a-XhAv3"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"vjF8PHUBtoVK","executionInfo":{"status":"ok","timestamp":1702074776210,"user_tz":-210,"elapsed":2788,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"outputs":[],"source":["# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n","\n","import torch\n","from torch import nn\n","\n","\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","\n","# helpers\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","# classes\n","\n","class PreNorm(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Attention(nn.Module):\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","        super().__init__()\n","        inner_dim = dim_head *  heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax(dim = -1)\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x):\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\n","        attn = self.attend(dots)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n","        super().__init__()\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n","                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n","            ]))\n","    def forward(self, x):\n","        for attn, ff in self.layers:\n","            x = attn(x) + x\n","            x = ff(x) + x\n","        return x\n","\n","class ViT(nn.Module):\n","    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n","        super().__init__()\n","        image_height, image_width = pair(image_size)\n","        patch_height, patch_width = pair(patch_size)\n","\n","        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n","\n","        num_patches = (image_height // patch_height) * (image_width // patch_width)\n","        patch_dim = channels * patch_height * patch_width\n","        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n","\n","        self.to_patch_embedding = nn.Sequential(\n","            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n","            nn.Linear(patch_dim, dim),\n","        )\n","\n","        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.dropout = nn.Dropout(emb_dropout)\n","\n","        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n","\n","        self.pool = pool\n","        self.to_latent = nn.Identity()\n","\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes)\n","        )\n","\n","    def forward(self, img):\n","        x = self.to_patch_embedding(img)\n","        b, n, _ = x.shape\n","\n","        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x += self.pos_embedding[:, :(n + 1)]\n","        x = self.dropout(x)\n","\n","        x = self.transformer(x)\n","\n","        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n","\n","        x = self.to_latent(x)\n","        return self.mlp_head(x)"]},{"cell_type":"markdown","source":["# Train On CIFAR10"],"metadata":{"id":"WqAa29qjgX-g"}},{"cell_type":"markdown","source":["## Libraries"],"metadata":{"id":"5gpPTCxykZ4l"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import os\n","import argparse\n","import pandas as pd\n","import csv\n","import time\n","\n","# from utils import progress_bar\n","# from randomaug import RandAugment"],"metadata":{"id":"5EUcLI6Qgbiq","executionInfo":{"status":"ok","timestamp":1702074776211,"user_tz":-210,"elapsed":30,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Hyper parameters"],"metadata":{"id":"Ex9oDanTkbPs"}},{"cell_type":"code","source":["# Hyper parameters\n","lr = 1e-4\n","bs = 512\n","size = 32\n","n_epochs = 20\n","patch = 4\n","dimhead = 512\n","\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YULoCBKUiJ72","executionInfo":{"status":"ok","timestamp":1702075343246,"user_tz":-210,"elapsed":5,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"a0273599-9a2b-4b9c-ad50-4cd70a0730b5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["## Load Dataset - Train/Test Loaders"],"metadata":{"id":"Ab1axAJ9kdhE"}},{"cell_type":"code","source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.Resize(size),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(size),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=8)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPtHlkOphv5m","executionInfo":{"status":"ok","timestamp":1702075226885,"user_tz":-210,"elapsed":2455,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"a40ad50a-9355-4ecb-d220-fe37903627d3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["## Build Model"],"metadata":{"id":"Ua93TxOEki-c"}},{"cell_type":"code","source":["net = ViT(\n","    image_size = size,\n","    patch_size = patch,\n","    num_classes = 10,\n","    dim = dimhead,\n","    depth = 6,\n","    heads = 8,\n","    mlp_dim = 512,\n","    dropout = 0.1,\n","    emb_dropout = 0.1\n",")\n","\n","net"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pGGJSytkkXrO","executionInfo":{"status":"ok","timestamp":1702075228301,"user_tz":-210,"elapsed":5,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"d823f85d-aa9b-46ed-daf8-49e1047eaaf1"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ViT(\n","  (to_patch_embedding): Sequential(\n","    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=4)\n","    (1): Linear(in_features=48, out_features=512, bias=True)\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (transformer): Transformer(\n","    (layers): ModuleList(\n","      (0-5): 6 x ModuleList(\n","        (0): PreNorm(\n","          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (fn): Attention(\n","            (attend): Softmax(dim=-1)\n","            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n","            (to_out): Sequential(\n","              (0): Linear(in_features=512, out_features=512, bias=True)\n","              (1): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1): PreNorm(\n","          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (fn): FeedForward(\n","            (net): Sequential(\n","              (0): Linear(in_features=512, out_features=512, bias=True)\n","              (1): GELU(approximate='none')\n","              (2): Dropout(p=0.1, inplace=False)\n","              (3): Linear(in_features=512, out_features=512, bias=True)\n","              (4): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (to_latent): Identity()\n","  (mlp_head): Sequential(\n","    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (1): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## Optimizer / Criterion"],"metadata":{"id":"JM0GXjlalVh3"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=lr)\n","\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n","\n","\n","num_parameters = sum(p.numel() for p in net.parameters() if p.requires_grad)\n","\n","print(f'number of parameters : {num_parameters}')\n","\n","scaler = torch.cuda.amp.GradScaler(enabled=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rP3_MEytlL7b","executionInfo":{"status":"ok","timestamp":1702075440311,"user_tz":-210,"elapsed":8,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"e2013e0e-06fa-4253-8208-eab08aebcb96"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["number of parameters : 9523722\n"]}]},{"cell_type":"markdown","source":["## Def Train/Test"],"metadata":{"id":"cYDHmLlbm1_T"}},{"cell_type":"code","source":["best_acc = 0\n","\n","def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        # Train with amp\n","        with torch.cuda.amp.autocast(enabled=True):\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","\n","    acc = 100.*correct/total\n","    # print(f'acc : {acc}')\n","\n","    return train_loss/(batch_idx+1), acc\n","\n","\n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","\n","    acc = 100.*correct/total\n","    # print(f'acc : {acc}')\n","\n","    return test_loss, acc\n"],"metadata":{"id":"RC3MZCO_m4Yr","executionInfo":{"status":"ok","timestamp":1702076617031,"user_tz":-210,"elapsed":2,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["## Train Model"],"metadata":{"id":"Y8rSXV9tn-AE"}},{"cell_type":"code","source":["train_list_loss = []\n","train_list_acc = []\n","\n","test_list_loss = []\n","test_list_acc = []\n","\n","net.cuda()\n","for epoch in range(0, n_epochs):\n","    start = time.time()\n","    trainloss,train_acc = train(epoch)\n","    val_loss, val_acc = test(epoch)\n","\n","    scheduler.step(epoch-1) # step cosine scheduling\n","\n","    train_list_loss.append(trainloss)\n","    train_list_acc.append(train_acc)\n","\n","    test_list_loss.append(val_loss)\n","    test_list_acc.append(val_acc)\n","\n","    print(f'epoch {epoch}, train loss = {trainloss}, train acc = {train_acc}, test loss = {val_loss}, test acc = {val_acc}, epoch time : {time.time()-start}, lr = {optimizer.param_groups[0][\"lr\"]}')\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcIJ-eZvn-gD","executionInfo":{"status":"ok","timestamp":1702077439950,"user_tz":-210,"elapsed":819220,"user":{"displayName":"Amir Mohammad Kharazi","userId":"18414030253865360797"}},"outputId":"ea817dba-15b2-401a-f283-496d638b418a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 0\n","epoch 0, train loss = 7.023257639943337, train acc = 14.928, test loss = 697.6976375579834, test acc = 14.9, epoch time : 42.170133113861084, lr = 9.938441702975689e-05\n","\n","Epoch: 1\n","epoch 1, train loss = 6.552092226184144, train acc = 14.7, test loss = 604.46044921875, test acc = 15.67, epoch time : 39.909051179885864, lr = 0.0001\n","\n","Epoch: 2\n","epoch 2, train loss = 5.50928918682799, train acc = 15.236, test loss = 502.34032249450684, test acc = 16.88, epoch time : 41.441991567611694, lr = 9.938441702975689e-05\n","\n","Epoch: 3\n","epoch 3, train loss = 4.554507211763031, train acc = 17.284, test loss = 437.2686836719513, test acc = 20.75, epoch time : 41.283379793167114, lr = 9.755282581475769e-05\n","\n","Epoch: 4\n","epoch 4, train loss = 4.053258569873109, train acc = 21.468, test loss = 404.33879351615906, test acc = 24.56, epoch time : 40.15654253959656, lr = 9.45503262094184e-05\n","\n","Epoch: 5\n","epoch 5, train loss = 3.7678627821863913, train acc = 23.69, test loss = 376.4938209056854, test acc = 25.8, epoch time : 40.97043180465698, lr = 9.045084971874738e-05\n","\n","Epoch: 6\n","epoch 6, train loss = 3.52104423727308, train acc = 24.886, test loss = 350.19088983535767, test acc = 26.78, epoch time : 41.20109820365906, lr = 8.535533905932738e-05\n","\n","Epoch: 7\n","epoch 7, train loss = 3.2805377585547313, train acc = 25.102, test loss = 325.23206877708435, test acc = 27.35, epoch time : 40.84930610656738, lr = 7.938926261462366e-05\n","\n","Epoch: 8\n","epoch 8, train loss = 3.055329369038952, train acc = 25.426, test loss = 301.6386797428131, test acc = 27.83, epoch time : 40.89665865898132, lr = 7.269952498697734e-05\n","\n","Epoch: 9\n","epoch 9, train loss = 2.8399422874256057, train acc = 25.628, test loss = 279.4894914627075, test acc = 27.98, epoch time : 41.076192140579224, lr = 6.545084971874738e-05\n","\n","Epoch: 10\n","epoch 10, train loss = 2.6357076849256242, train acc = 25.75, test loss = 259.3510694503784, test acc = 28.45, epoch time : 40.70518660545349, lr = 5.782172325201155e-05\n","\n","Epoch: 11\n","epoch 11, train loss = 2.4612300249995016, train acc = 26.214, test loss = 241.901593208313, test acc = 28.8, epoch time : 40.85943269729614, lr = 5e-05\n","\n","Epoch: 12\n","epoch 12, train loss = 2.3137919756830954, train acc = 26.388, test loss = 228.1579189300537, test acc = 29.05, epoch time : 42.16062831878662, lr = 4.217827674798847e-05\n","\n","Epoch: 13\n","epoch 13, train loss = 2.20458076194841, train acc = 26.814, test loss = 218.5265748500824, test acc = 29.25, epoch time : 39.9508638381958, lr = 3.4549150281252636e-05\n","\n","Epoch: 14\n","epoch 14, train loss = 2.137321374854263, train acc = 27.06, test loss = 212.39432382583618, test acc = 29.39, epoch time : 41.03421139717102, lr = 2.7300475013022663e-05\n","\n","Epoch: 15\n","epoch 15, train loss = 2.0942636703958315, train acc = 27.506, test loss = 208.6020942926407, test acc = 29.56, epoch time : 41.22712278366089, lr = 2.061073738537635e-05\n","\n","Epoch: 16\n","epoch 16, train loss = 2.069982134566015, train acc = 27.61, test loss = 206.31113576889038, test acc = 29.74, epoch time : 39.87516212463379, lr = 1.4644660940672627e-05\n","\n","Epoch: 17\n","epoch 17, train loss = 2.0536637549497643, train acc = 27.846, test loss = 204.92634654045105, test acc = 29.9, epoch time : 42.55361485481262, lr = 9.549150281252633e-06\n","\n","Epoch: 18\n","epoch 18, train loss = 2.0462326054670372, train acc = 27.848, test loss = 204.09637796878815, test acc = 30.08, epoch time : 40.11669611930847, lr = 5.449673790581611e-06\n","\n","Epoch: 19\n","epoch 19, train loss = 2.043370492604314, train acc = 28.308, test loss = 203.64966595172882, test acc = 30.09, epoch time : 40.78061532974243, lr = 2.4471741852423237e-06\n"]}]}]}